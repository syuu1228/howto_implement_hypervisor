static void *
fbsdrun_start_thread(void *param)
{
	char tname[MAXCOMLEN + 1];
	struct mt_vmm_info *mtp;
	int vcpu;

	mtp = param;
	vcpu = mtp->mt_vcpu;

	snprintf(tname, sizeof(tname), "%s vcpu %d", vmname, vcpu);
	pthread_set_name_np(mtp->mt_thr, tname);

	vm_loop(mtp->mt_ctx, vcpu, vmexit[vcpu].rip);                   (17)

	/* not reached */
	exit(1);
	return (NULL);
}

void
fbsdrun_addcpu(struct vmctx *ctx, int vcpu, uint64_t rip)
{
	int error;

	if (cpumask & (1 << vcpu)) {
		fprintf(stderr, "addcpu: attempting to add existing cpu %d\n",
		    vcpu);
		exit(1);
	}

	cpumask |= 1 << vcpu;
	foundcpus++;

	/*
	 * Set up the vmexit struct to allow execution to start
	 * at the given RIP
	 */
	vmexit[vcpu].rip = rip;
	vmexit[vcpu].inst_length = 0;

	if (vcpu == BSP || !guest_vcpu_mux){
		mt_vmm_info[vcpu].mt_ctx = ctx;
		mt_vmm_info[vcpu].mt_vcpu = vcpu;
	
		error = pthread_create(&mt_vmm_info[vcpu].mt_thr, NULL,
				fbsdrun_start_thread, &mt_vmm_info[vcpu]);          (16)
		assert(error == 0);
	}
}
......(省略)......
static vmexit_handler_t handler[VM_EXITCODE_MAX] = {                (22)
	[VM_EXITCODE_INOUT]  = vmexit_inout,
	[VM_EXITCODE_VMX]    = vmexit_vmx,
	[VM_EXITCODE_BOGUS]  = vmexit_bogus,
	[VM_EXITCODE_RDMSR]  = vmexit_rdmsr,
	[VM_EXITCODE_WRMSR]  = vmexit_wrmsr,
	[VM_EXITCODE_MTRAP]  = vmexit_mtrap,
	[VM_EXITCODE_PAGING] = vmexit_paging,
	[VM_EXITCODE_SPINUP_AP] = vmexit_spinup_ap,
};

static void
vm_loop(struct vmctx *ctx, int vcpu, uint64_t rip)
{
	int error, rc, prevcpu;

	if (guest_vcpu_mux)
		setup_timeslice();

	if (pincpu >= 0) {
		error = vm_set_pinning(ctx, vcpu, pincpu + vcpu);
		assert(error == 0);
	}

	while (1) {
		error = vm_run(ctx, vcpu, rip, &vmexit[vcpu]);              (18)
		if (error != 0) {
			/*
			 * It is possible that 'vmmctl' or some other process
			 * has transitioned the vcpu to CANNOT_RUN state right
			 * before we tried to transition it to RUNNING.
			 *
			 * This is expected to be temporary so just retry.
			 */
			if (errno == EBUSY)
				continue;
			else
				break;
		}

		prevcpu = vcpu;
                rc = (*handler[vmexit[vcpu].exitcode])(ctx, &vmexit[vcpu],
                                                       &vcpu);		(21)
		switch (rc) {                                               (23)
                case VMEXIT_SWITCH:
			assert(guest_vcpu_mux);
			if (vcpu == -1) {
				stats.cpu_switch_rotate++;
				vcpu = fbsdrun_get_next_cpu(prevcpu);
			} else {
				stats.cpu_switch_direct++;
			}
			/* fall through */
		case VMEXIT_CONTINUE:
                        rip = vmexit[vcpu].rip + vmexit[vcpu].inst_length;
			break;
		case VMEXIT_RESTART:
                        rip = vmexit[vcpu].rip;
			break;
		case VMEXIT_RESET:
			exit(0);
		default:
			exit(1);
		}
	}
	fprintf(stderr, "vm_run error %d, errno %d\n", error, errno);
}
......(省略)......
int
main(int argc, char *argv[])
{
......(省略)......

	while ((c = getopt(argc, argv, "abehABHIPxp:g:c:z:s:S:n:m:M:")) != -1) {
......(省略)......
	vmname = argv[0];

	ctx = vm_open(vmname);                                          (1)
	if (ctx == NULL) {
		perror("vm_open");
		exit(1);
	}
......(省略)......
	if (lomem_sz != 0) {
		lomem_addr = vm_map_memory(ctx, 0, lomem_sz);               (5)
		if (lomem_addr == (char *) MAP_FAILED) {
			lomem_sz = 0;
		} else if (himem_sz != 0) {
			himem_addr = vm_map_memory(ctx, 4*GB, himem_sz);        (7)
			if (himem_addr == (char *) MAP_FAILED) {
				lomem_sz = 0;
				himem_sz = 0;
			}
		}
	}

	init_inout();                                                   (8)
	init_pci(ctx);                                                  (9)
	if (ioapic)
		ioapic_init(0);                                             (10)
......(省略)......
	error = vm_get_register(ctx, BSP, VM_REG_GUEST_RIP, &rip);      (11)
	assert(error == 0);
......(省略)......
	/*
	 * build the guest tables, MP etc.
	 */
	mptable_build(ctx, guest_ncpus, ioapic);                        (13)

	if (acpi) {
		error = acpi_build(ctx, guest_ncpus, ioapic);               (14)
		assert(error == 0);
	}

	/*
	 * Add CPU 0
	 */
	fbsdrun_addcpu(ctx, BSP, rip);                                  (15)


(1) getoptで処理されなかった一番端の引数がVM名となります。
    libvmmapiを用いてVM名に対応するデバイスファイルをオープンします。

(2) vm_open()はstruct vmctxをアロケートし、

(3) vmctx->fdにファイルディスクリプタを保存します。

(4) vm_device_open()は/dev/vmm/${name}を読み書き用でオープンします。

(5) 4GB未満のゲストメモリ空間をlomem_addrへマッピングします。

(6) /dev/vmm/${name}をmmap()します。
    vmm.koからゲストメモリ空間のアドレスが渡されます。

(7) 4GB以上のゲストメモリ空間をhimem_addrへマッピングします。

(8) IOポートエミュレーションの初期化を行います。

(9) PCIデバイスエミュレーションの初期化を行います。

(10)IO APICエミュレーションの初期化を行います。

(11)/usr/sbin/bhyveloadで設定されたRIPレジスタの値を取得します。

(12)/dev/vmm/${name}へVM_GET_REGISTER ioctlを行います。
    vmm.koからレジスタの値が渡されます。

(13)MPテーブルを生成します。2つ以上のCPU数で起動する時に必要です。

(14)ACPIテーブルを生成します。無変更なFreeBSDカーネルを起動するのに必要です。

(15)cpu0（BSP）のスレッドを起動します。実行開始アドレスとしてRIPを渡します。

(16)pthread_create(fbsdrun_start_thread)します。
    ここまでがハイパーバイザの初期化の処理になります。
    ここからはゲストマシンの実行処理に移っていきます。

(17)vm_loop()で仮想CPUを実行します。

(18)whileループの中でvm_run()を呼びます。

(19)/dev/vmm/${name}へVM_RUN ioctlを行います。
    vmm.koはこのスレッドが実行されているCPUをVT-x non root modeへ移行し、
    vmrun.ripで指定されたアドレスから実行を開始します。

(20)VMX non root modeでハイパーバイザの介入が必要な何らかのイベントが発生すると
    vmm.koの中でトラップされ、/usr/sbin/bhyveでイベントを処理する必要がある場合は
    ioctlがリターンされます。
    リターンされた理由をvmm.koからstruct vmexitで受け取ります。

(21)ioctlリターンの理由（vmexit.exitcode）に対応したイベントハンドラ（handler[]）を呼
    び出します。

(22)/usr/sbin/bhyveに定義されているhandler[]です。
    IOポートへのアクセス、MSRレジスタの読み書き、メモリマップドIO、セカンダリ
    CPUの起動シグナルなどがハンドラとして定義されています。

(23)handler[]からの返り値により、CPUを現在のripから再開するか・次の命令から再開す
    るか・ハイパーバイザの実行を中止するか、などの処理を行なっています。
    実行が再開される場合は、whileループにより再びvm_loop()の実行に戻ります。


